# Microsoft Certified: Azure Data Scientist Associate 

## Designing and implementing a data science solution on Azure

### Explore and configure the Azure Machine Learning workspace 

#### Explore Azure Machine Learning workspace resource and assets


# Azure Machine Learning Terms and Concepts

## 1. Azure Machine Learning Platform

- **Azure Machine Learning (AML)**  
  A cloud-based platform that provides tools and services for data scientists to train, deploy, and manage machine learning models on Microsoft Azure.

- **Azure Machine Learning Workspace**  
  The central top-level resource in AML where all resources and assets (datasets, models, compute, etc.) are organized and managed for machine learning projects.

- **Azure Machine Learning Studio**  
  A web portal interface launched from the Azure portal to create, manage, and use Azure Machine Learning resources and assets.

- **Azure Machine Learning Service**  
  The service in an Azure subscription that allows creation and management of machine learning workspaces and resources.

## 2. Compute Services

- **Compute**  
  The cloud infrastructure that provides the computational power needed to run machine learning workflows (training, inference, etc.).

- **Compute Instance**  
  A virtual machine (VM) in Azure specifically provisioned for individual development and experimentation, often used for notebooks or debugging.

- **Compute Clusters**  
  Scalable, on-demand clusters of CPU or GPU nodes used to distribute and accelerate training jobs in the cloud.

- **Kubernetes Clusters**  
  Azure Kubernetes Service (AKS) clusters used to orchestrate containers for scalable model deployment or batch inferencing.

- **Attached Computes**  
  External compute resources, like an existing AKS cluster, connected to the Azure Machine Learning workspace to run jobs.

- **Serverless Computes**  
  Compute resources that run workloads without the user managing the underlying infrastructure, typically for lightweight or event-driven ML tasks.

## 3. Storage and Data Management

- **Datastore**  
  References or connections to Azure data storage services (e.g., Blob Storage, Data Lake) where data is stored outside the workspace.

- **Azure Storage Account**  
  An Azure resource created alongside the workspace, providing persistent storage (blobs, files) used by the workspace for datasets, outputs, and other artifacts.

- **Data Asset**  
  A specific file or folder registered in the workspace that points to actual data within datastores or storage services.

- **Azure Key Vault**  
  A secure service where sensitive information like connection strings, secrets, and credentials are stored. Used to protect datastore connection information.

## 4. Identity and Access Management

- **Azure Portal**  
  The primary web interface for managing all Azure services, including the Azure Machine Learning workspace and resources.

- **Access Control**  
  Mechanism to assign and manage permissions for users or teams to access Azure resources.

- **Role-Based Access Control (RBAC)**  
  Azureâ€™s authorization system to manage access by assigning roles to users/groups, controlling who can view or manage specific resources such as the AML workspace or compute.

## 5. Development and Deployment Assets

- **Models**  
  The trained machine learning artifacts created with frameworks like Scikit-learn or PyTorch, registered in the workspace with name and version for deployment and tracking.

- **Environments**  
  Define the software dependencies, environment variables, and configurations required to run machine learning scripts or code on compute resources. Stored as container images in Azure Container Registry.

- **Components**  
  Reusable code units or steps (e.g., data preprocessing, model training) that can be assembled into pipelines within the workspace. Components specify code, environment, and version.

- **Pipelines**  
  Orchestrated workflows built by chaining components to automate complex machine learning tasks.

## 6. Machine Learning Workflow Features

- **Automated Machine Learning (AutoML)**  
  A feature that automates the process of algorithm selection and hyperparameter tuning to find the best performing model for a dataset.

- **Notebooks**  
  Interactive code environments hosted in the workspace, typically run on compute instances, used for exploration and experimentation.

- **Jobs**  
  Executions of scripts or training runs submitted to the Azure Machine Learning workspace. Jobs store all inputs, outputs, and logs for reproducibility.

## 7. Supporting Azure Services

- **Azure Container Registry (ACR)**  
  A private registry service in Azure to store and manage container images, such as those created for environments in AML.

---

## Relationships and Summary

- The **Azure Machine Learning workspace** ties everything together: it contains compute resources (compute instances, clusters, Kubernetes, serverless), data storage (datastores, data assets), and assets (models, environments, components).

- **Access control (RBAC)** ensures proper permissions for users to interact with these resources safely.

- **Compute** is essential for running experiments, either interactively via notebooks on compute instances or through jobs running scripts on clusters or serverless compute.

- **Environments** package dependencies and configurations needed for consistent execution across compute.

- **Automated ML** is a high-level feature to speed up model training without manually testing algorithms or hyperparameters.


Azure Machine Learning provides a platform for data scientists to train, deploy, and manage their machine learning models on the Microsoft Azure platform. Azure Machine Learning provides a comprehensive set of resources and assets to train and deploy effective machine learning models.

To get access to an Azure Machine Learning workspace, you first need to create the Azure Machine Learning service in your Azure subscription. The workspace is central place where you can work with all resources and assets available to train and deploy machine learning models.

From the Overview page of the Azure Machine Learning workspace in the Azure portal, you can launch the Azure Machine Learning studio. The Azure Machine Learning studio is a web portal and provides an easy-to-use interface to create, manage, and use resources and assets in the workspace.

From the Azure portal, you can also give others access to the Azure Machine Learning workspace, using the Access control. You can give individual users or teams access to the Azure Machine Learning workspace. Access is granted in Azure using role-based access control (RBAC), which you can configure in the Access control tab of the resource or resource group.

You can use workspaces to group machine learning assets based on projects, deployment environments (for example, test and production), teams, or some other organizing principle.

Resources in Azure Machine Learning refer to the infrastructure you need to run a machine learning workflow. The workspace is the top-level resource for Azure Machine Learning. Data scientists need access to the workspace to train and track models, and to deploy the models to endpoints. However, you want to be careful with who has full access to the workspace. 

One of the most important resources you need when training or deploying a model is compute. There are five types of compute in the Azure Machine Learning workspace: Compute instance (vm in the cloud); Compute clusters (on-demand clusters of CPU/GPU nodes in the cloud); Kubernet clusters; Attached computes (AKS cluster); Serverless computes. Though compute is the most important resource when working with machine learning workloads, it can also be the most cost-intensive. Therefore, a best practice is to only allow administrators to create and manage compute resources. Data scientists shouldn't be allowed to edit compute, but only use the available compute to run their workloads. 

The workspace doesn't store any data itself. Instead, all data is stored in datastores, which are references to Azure data services. The connection information to a data service that a datastore represents, is stored in the Azure Key Vault. When a workspace is created, an Azure Storage account is created and automatically connected to the workspace. As a result, you have four datastores already added to your workspace. Additionally, you can create datastores to connect to other Azure data services.

As a data scientist, you mostly work with assets in the Azure Machine Learning workspace. Assets are created and used at various stages of a project.

The end product of training a model is the model itself. You can train machine learning models with various frameworks, like Scikit-learn or PyTorch. When you create a model in the workspace, you specify the name and version. Especially useful when you deploy the registered model, versioning allows you to track the specific model you want to use.

When you work with cloud compute, it's important to ensure that your code runs on any compute that is available to you. Whether you want to run a script on a compute instance, or a compute cluster, the code should execute successfully. When you write code that uses any frameworks or libraries, you need to ensure the necessary dependencies are installed on the compute that executes the code. To list all necessary requirements, you can create environments. When you create an environment, you have to specify the name and version. Environments specify software packages, environment variables, and software settings to run scripts. An environment is stored as an image in the Azure Container Registry created with the workspace when it's used for the first time.

Whereas datastores contain the connection information to Azure data storage services, data assets refer to a specific file or folder. When you create a data asset in the workspace, you specify the path to point to the file or folder, and the name and version.

To train machine learning models, you write code. Across projects, there can be code you can reuse. Instead of writing code from scratch, you want to reuse snippets of code from other projects. To make it easier to share code, you can create a component in a workspace. To create a component, you have to specify the name, version, code, and environment needed to run the code. You can use components when creating pipelines. A component therefore often represents a step in a pipeline, for example to normalize data, to train a regression model, or to test the trained model on a validation dataset.

To train models with the Azure Machine Learning workspace, you have several options. When you have a training dataset and you're tasked with finding the best performing model, you might want to experiment with various algorithms and hyperparameter values. Automated Machine Learning iterates through algorithms paired with feature selections to find the best performing model for your data.

When you prefer to develop by running code in notebooks, you can use the built-in notebook feature in the workspace. All files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace. To run notebooks, you use a compute instance as they're ideal for development and work similar to a virtual machine.

When you want to prepare your code to be production ready, it's better to use scripts. You can easily automate the execution of script to automate any machine learning workload. You can run a script as a job in Azure Machine Learning. When you submit a job to the workspace, all inputs and outputs are stored in the workspace.
