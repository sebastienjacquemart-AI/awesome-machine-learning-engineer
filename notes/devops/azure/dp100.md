# Microsoft Certified: Azure Data Scientist Associate 

## Designing and implementing a data science solution on Azure

### Explore and configure the Azure Machine Learning workspace 

#### Explore Azure Machine Learning workspace resource and assets

Azure Machine Learning provides a platform for data scientists to train, deploy, and manage their machine learning models on the Microsoft Azure platform. Azure Machine Learning provides a comprehensive set of resources and assets to train and deploy effective machine learning models.

To get access to an Azure Machine Learning workspace, you first need to create the Azure Machine Learning service in your Azure subscription. The workspace is central place where you can work with all resources and assets available to train and deploy machine learning models.

From the Overview page of the Azure Machine Learning workspace in the Azure portal, you can launch the Azure Machine Learning studio. The Azure Machine Learning studio is a web portal and provides an easy-to-use interface to create, manage, and use resources and assets in the workspace.

From the Azure portal, you can also give others access to the Azure Machine Learning workspace, using the Access control. You can give individual users or teams access to the Azure Machine Learning workspace. Access is granted in Azure using role-based access control (RBAC), which you can configure in the Access control tab of the resource or resource group.

You can use workspaces to group machine learning assets based on projects, deployment environments (for example, test and production), teams, or some other organizing principle.

Resources in Azure Machine Learning refer to the infrastructure you need to run a machine learning workflow. The workspace is the top-level resource for Azure Machine Learning. Data scientists need access to the workspace to train and track models, and to deploy the models to endpoints. However, you want to be careful with who has full access to the workspace. 

One of the most important resources you need when training or deploying a model is compute. There are five types of compute in the Azure Machine Learning workspace: Compute instance (vm in the cloud); Compute clusters (on-demand clusters of CPU/GPU nodes in the cloud); Kubernet clusters; Attached computes (AKS cluster); Serverless computes. Though compute is the most important resource when working with machine learning workloads, it can also be the most cost-intensive. Therefore, a best practice is to only allow administrators to create and manage compute resources. Data scientists shouldn't be allowed to edit compute, but only use the available compute to run their workloads. 

The workspace doesn't store any data itself. Instead, all data is stored in datastores, which are references to Azure data services. The connection information to a data service that a datastore represents, is stored in the Azure Key Vault. When a workspace is created, an Azure Storage account is created and automatically connected to the workspace. As a result, you have four datastores already added to your workspace. Additionally, you can create datastores to connect to other Azure data services.

As a data scientist, you mostly work with assets in the Azure Machine Learning workspace. Assets are created and used at various stages of a project.

The end product of training a model is the model itself. You can train machine learning models with various frameworks, like Scikit-learn or PyTorch. When you create a model in the workspace, you specify the name and version. Especially useful when you deploy the registered model, versioning allows you to track the specific model you want to use.

When you work with cloud compute, it's important to ensure that your code runs on any compute that is available to you. Whether you want to run a script on a compute instance, or a compute cluster, the code should execute successfully. When you write code that uses any frameworks or libraries, you need to ensure the necessary dependencies are installed on the compute that executes the code. To list all necessary requirements, you can create environments. When you create an environment, you have to specify the name and version. Environments specify software packages, environment variables, and software settings to run scripts. An environment is stored as an image in the Azure Container Registry created with the workspace when it's used for the first time.

Whereas datastores contain the connection information to Azure data storage services, data assets refer to a specific file or folder. When you create a data asset in the workspace, you specify the path to point to the file or folder, and the name and version.

To train machine learning models, you write code. Across projects, there can be code you can reuse. Instead of writing code from scratch, you want to reuse snippets of code from other projects. To make it easier to share code, you can create a component in a workspace. To create a component, you have to specify the name, version, code, and environment needed to run the code. You can use components when creating pipelines. A component therefore often represents a step in a pipeline, for example to normalize data, to train a regression model, or to test the trained model on a validation dataset.

To train models with the Azure Machine Learning workspace, you have several options. When you have a training dataset and you're tasked with finding the best performing model, you might want to experiment with various algorithms and hyperparameter values. Automated Machine Learning iterates through algorithms paired with feature selections to find the best performing model for your data.

When you prefer to develop by running code in notebooks, you can use the built-in notebook feature in the workspace. All files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace. To run notebooks, you use a compute instance as they're ideal for development and work similar to a virtual machine.

When you want to prepare your code to be production ready, it's better to use scripts. You can easily automate the execution of script to automate any machine learning workload. You can run a script as a job in Azure Machine Learning. When you submit a job to the workspace, all inputs and outputs are stored in the workspace.
